# ğŸ©º AI Doctor VoiceBot

AI Doctor VoiceBot is a multimodal application that allows users to describe symptoms through voice, upload a medical image (such as a skin condition), and receive a realistic doctor-style response both in text and voice form. It combines speech recognition, image understanding, and language generation, powered by the Groq API.

---

## âœ¨ Features

- ğŸ¤ Voice input recording using `sounddevice`
- ğŸ§  Speech-to-text using Whisper via Groq API
- ğŸ–¼ï¸ Medical image analysis using LLaMA Vision models
- ğŸ’¬ Human-like doctor responses based on symptoms and image
- ğŸ”Š Text-to-speech using Google TTS (`gTTS`)
- ğŸŒ Web interface using Gradio

---

## ğŸ› ï¸ Technologies Used

| Component           | Technology              |
|---------------------|--------------------------|
| User Interface      | Gradio                   |
| Audio Input         | sounddevice, soundfile   |
| Speech-to-Text      | Whisper (Groq API)       |
| Image Reasoning     | LLaMA Vision (Groq API)  |
| Text-to-Speech      | gTTS (Google TTS)        |
| Environment Config  | dotenv (`.env`)          |
| Audio Conversion    | Pydub (optional)         |

---

## ğŸ§  How It Works

1. **ğŸ¤ Patient speaks** a symptom or concern using the microphone.
2. **ğŸ“„ Whisper model** (via Groq API) transcribes the speech to text.
3. **ğŸ–¼ï¸ Patient uploads** an image (e.g., skin condition, rash, etc.).
4. **ğŸ§  LLaMA Vision model** analyzes the image and combines it with the transcribed symptom.
5. **ğŸ©º A doctor-style response** is generated using Groqâ€™s multimodal LLM.
6. **ğŸ”Š gTTS** converts the response to speech and plays it back to the user.

This creates a smooth multimodal flow from patient input to intelligent, human-like AI response.

### ğŸ“· Example UI

<img width="488" alt="Voicebot_UI" src="https://github.com/user-attachments/assets/f433c0dc-4bc0-4efd-b260-f476e18dcbe0" />


## ğŸ—‚ï¸ Project Structure

ai-doctor-voicebot/
â”œâ”€â”€ brain_of_the_doctor.py # Image processing and Groq Vision query
â”œâ”€â”€ voice_of_the_patient.py # Audio recording and transcription logic
â”œâ”€â”€ voice_of_the_doctor.py # Text-to-speech conversion using gTTS
â”œâ”€â”€ voice_doctor_ui.py # Main Gradio interface
â”œâ”€â”€ requirements.txt # Python dependencies
â”œâ”€â”€ .env # Environment variables (not pushed to GitHub)
â””â”€â”€ README.md # Project documentation

## âš™ï¸ Setup Instructions

# Project Setup Guide â€“ AI Doctor VoiceBot

## 1. Clone the repository

git clone https://github.com/Huzaifa-202/ai-doctor-voicebot.git
cd ai-doctor-voicebot

## 2. Create and activate a virtual environment

python -m venv ai-medical-voicebot
ai-medical-voicebot\Scripts\activate

## 3. Install dependencies

pip install -r requirements.txt

## 4. Add your Groq API key

Create a `.env` file in the root directory with the following content:

GROQ_API_KEY=your_groq_api_key_here

## 5. Run the app

python voice_doctor_ui.py

Open your browser and go to:

http://localhost:7860

## ğŸ“¦ Dependencies

gradio
sounddevice
soundfile
gtts
pydub
python-dotenv
groq
ffmpeg

## ğŸ™ Acknowledgements

Groq â€“ for high-speed inference with Whisper and LLaMA

OpenAI Whisper â€“ for transcription

Google TTS (gTTS) â€“ for text-to-speech

Gradio â€“ for the user interface

Pydub â€“ for audio conversion


